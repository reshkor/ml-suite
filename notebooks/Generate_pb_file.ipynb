{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a inference protobuf from Tensorflow trained model\n",
    "In this example, we will take a caffe example and convert it into tensorflow model.<br>\n",
    "I am using an open source library caffe-tensorflow, https://github.com/ethereon/caffe-tensorflow <br>\n",
    "If tf.Session() has access to the trained graph, please skip first 6 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wrk/hdstaff/satyakee/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to github work directory and clone https://github.com/ethereon/caffe-tensorflow repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/'.join(os.getcwd().split('/')[:-2]) + '/caffe-tensorflow')\n",
    "sys.path.insert(0, '/'.join(os.getcwd().split('/')[:-2]) + '/caffe-tensorflow/examples/imagenet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named kaffe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1a7dfd102f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkaffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKaffeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_stderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorFlowTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named kaffe"
     ]
    }
   ],
   "source": [
    "from kaffe import KaffeError, print_stderr\n",
    "from kaffe.tensorflow import TensorFlowTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports for building tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set outputs for the data and code for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_path = '/'.join(os.getcwd().split('/')[:-2]) + '/caffe-tensorflow/model/bvlc_googlenet_without_lrn_deploy.prototxt'\n",
    "caffemodel_path = '/'.join(os.getcwd().split('/')[:-2]) + '/caffe-tensorflow/model/bvlc_googlenet_without_lrn.caffemodel'\n",
    "phase = 'test'\n",
    "data_output_path = 'tf_data'\n",
    "code_output_path = 'tf_out'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks if the output files are properly given or not and writes the tf code(prepares the layers) and data in to the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    transformer = TensorFlowTransformer(def_path, caffemodel_path, phase=phase)\n",
    "    print_stderr('Converting data...')\n",
    "    if caffemodel_path is not None:\n",
    "        data = transformer.transform_data()\n",
    "        print_stderr('Saving data...')\n",
    "        with open(data_output_path, 'wb') as data_out:\n",
    "            np.save(data_out, data)\n",
    "    if code_output_path:\n",
    "        print_stderr('Saving source...')\n",
    "        with open(code_output_path, 'wb') as src_out:\n",
    "            src_out.write(transformer.transform_source())\n",
    "    print_stderr('Done.')\n",
    "except KaffeError as err:\n",
    "    fatal_error('Error encountered: {}'.format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reset the default graph in tensorflow <br>\n",
    "Get the spec data from models and create the placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "spec = models.get_data_spec(model_class=models.GoogleNet)\n",
    "input_node = tf.placeholder(tf.float32,\n",
    "                    shape=(None, spec.crop_size, spec.crop_size, spec.channels), name='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the image and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/'.join(os.getcwd().split('/')[:-2]) + '/caffe-tensorflow/examples/imagenet/cat.jpg'\n",
    "#    fname = 'fish-bike.jpg'\n",
    "\n",
    "image1 = tf.image.decode_jpeg(tf.read_file(fname), channels=3)\n",
    "batch1out = tf.expand_dims(image1,0)\n",
    "resized1  = tf.image.resize_images(batch1out,  [spec.crop_size, spec.crop_size], tf.image.ResizeMethod.BILINEAR)\n",
    "\n",
    "# Convert RGB to BGR\n",
    "red,green,blue = tf.unstack(resized1, axis=-1)\n",
    "resized2 = tf.stack([blue, green, red], axis=-1)\n",
    "\n",
    "# Values used in CAFFE based on BGR...\n",
    "IMG_MEAN = np.array((104.006989,116.66877,122.678917), dtype=np.float32)\n",
    "mean_image = tf.subtract(resized2, IMG_MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the network\n",
    "\n",
    "net = models.GoogleNet({'data': input_node})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The below method creates inference graph from tensorflow trained graph and writes it to a protobuf file <br>\n",
    "Also, note the train_writer writes the graph to logs in final_inference_graph. Below are the steps to see the final graph in tensorboard<br>\n",
    "1. cd to current directory<br>\n",
    "2. tensorboard --logdir=final_inference_graph\n",
    "3. http://[server-name]:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to list if desired...\n",
    "def freeze_graph(fname, sess, outputnode):\n",
    "    if type(outputnode) == tf.Tensor:\n",
    "        outputname = outputnode.op.name\n",
    "    else:\n",
    "        outputname = outputnode\n",
    "    graph_def_freeze = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, [outputname])\n",
    "    graph_def = tf.graph_util.remove_training_nodes(graph_def_freeze, [outputname])\n",
    "    pure_inference = tf.graph_util.extract_sub_graph(graph_def,[outputname])\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter(\"final_inference_graph\", sess.graph)\n",
    "    train_writer.flush()\n",
    "    train_writer.close()\n",
    "\n",
    "    with tf.gfile.GFile(fname, \"wb\") as f:\n",
    "        f.write(pure_inference.SerializeToString())\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing if the model is working properly using cat.jpg results will give the probability that the image is cat or not<br><br>\n",
    "\n",
    "Also, note the train_writer writes the graph to logs in logs. Below are the steps to see the imported graph in tensorboard<br>\n",
    "1. cd to current directory<br>\n",
    "2. tensorboard --logdir=final_inference_graph\n",
    "3. http://[server-name]:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = None\n",
    "with tf.Session() as sess:\n",
    "    # Load the converted parameters\n",
    "    #instrumentNodes = instrument_graph(tf.get_default_graph())\n",
    "    print('Loading the model')\n",
    "    net.load(data_output_path, sess)\n",
    "    train_writer = tf.summary.FileWriter(\"logs\", sess.graph)\n",
    "    img_data = mean_image.eval()\n",
    "    #results = sess.run([net.get_output(), instrumentNodes], feed_dict={input_node: img_data})\n",
    "    results = sess.run(net.get_output(), feed_dict={input_node: img_data})\n",
    "    train_writer.flush()\n",
    "    freeze_graph(\"test.pb\", sess, net.get_output())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results array from previous cell, display the results in human readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(image_paths, probs):\n",
    "    '''Displays the classification results given the class probability for each image'''\n",
    "    # Get a list of ImageNet class labels\n",
    "    with open('/'.join(os.getcwd().split('/')[:-1]) + '/caffe-tensorflow/examples/imagenet/imagenet-classes.txt', 'rb') as infile:\n",
    "        class_labels = map(str.strip, infile.readlines())\n",
    "    # Pick the class with the highest confidence for each image\n",
    "    class_indices = np.argmax(probs, axis=1)\n",
    "    # Display the results\n",
    "    print('\\n{:20} {:30} {}'.format('Image', 'Classified As', 'Confidence'))\n",
    "    print('-' * 70)\n",
    "    for img_idx, image_path in enumerate(image_paths):\n",
    "        img_name = osp.basename(image_path)\n",
    "        class_name = class_labels[class_indices[img_idx]]\n",
    "        confidence = round(probs[img_idx, class_indices[img_idx]] * 100, 2)\n",
    "        print('{:20} {:30} {} %'.format(img_name, class_name, confidence))\n",
    "display_results([fname], results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
